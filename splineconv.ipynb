{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darkzard05/Cora_dataset_benchmark/blob/main/splineconv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U_rypC--3Mc",
        "outputId": "43bc2a6f-1e98-4ee3-acf6-083384ac5ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 11.1 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=cfa38bafc59e391cb8b74ec07083ca05f87e983edcb72dabf8db0cd0fc6dcc34\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4 torch-scatter-2.0.9 torch-sparse-0.6.13 torch-spline-conv-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter torch-sparse torch-spline-conv torch_geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8-smDMP-9e3",
        "outputId": "76255634-2f89-47fd-977b-a434292818b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch_geometric\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import SplineConv\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWyd8fOJCGNb",
        "outputId": "4b3114a9-dd19-4d08-b84e-8b05c2ebdcb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'Cora'\n",
        "dataset = Planetoid(root='/tmp/'+dataset_name, name=dataset_name, \n",
        "                    transform=T.TargetIndegree()\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4xBJPAHEcxZ",
        "outputId": "020c5a0b-8b2a-476d-8b88-bf651acbad7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset name: Cora\n",
            "number of nodes: 2708 // number of edges: 10556 // number of classes: 7\n",
            "number of node features: 1433 // number of edge features: 1\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
            "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]]) tensor([[0.0179],\n",
            "        [0.0238],\n",
            "        [0.0179],\n",
            "        ...,\n",
            "        [0.1964],\n",
            "        [0.0238],\n",
            "        [0.0238]]) tensor([3, 4, 4,  ..., 3, 3, 3])\n",
            "tensor(140) tensor(500) tensor(1000)\n"
          ]
        }
      ],
      "source": [
        "data = dataset[0]\n",
        "print(f'dataset name: {dataset_name}')\n",
        "print(f'number of nodes: {data.num_nodes} // number of edges: {data.num_edges} // number of classes: {dataset.num_classes}')\n",
        "print(f'number of node features: {data.num_node_features} // number of edge features: {data.num_edge_features}')\n",
        "print(data.x, data.edge_index, data.edge_attr, data.y)\n",
        "print(data.train_mask.sum(), data.val_mask.sum(), data.test_mask.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wo1cagCCnEoT"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super().__init__()\n",
        "        self.layer1 = SplineConv(data.num_node_features, hidden, dim=1, kernel_size=2)\n",
        "        self.layer2 = SplineConv(hidden, dataset.num_classes, dim=1, kernel_size=2)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.layer1.reset_parameters()\n",
        "        self.layer2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.layer1(x, edge_index, edge_attr).relu()\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.layer2(x, edge_index, edge_attr).relu()\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9bBboRu4q0I",
        "outputId": "6b75c89a-c72e-4bcb-e0e5-2cd52fdf3f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available\n",
            "Model(\n",
            "  (layer1): SplineConv(1433, 16, dim=1)\n",
            "  (layer2): SplineConv(16, 7, dim=1)\n",
            ")\n",
            "{'layer1.weight': [2, 1433, 16], 'layer1.bias': [16], 'layer1.lin.weight': [16, 1433], 'layer2.weight': [2, 16, 7], 'layer2.bias': [7], 'layer2.lin.weight': [7, 16]}\n",
            "epoch: 1 | loss: 1.9470 | train_acc: 0.5929 | val_acc: 0.314 | test_acc: 0.344\n",
            "epoch: 2 | loss: 1.9058 | train_acc: 0.7357 | val_acc: 0.42 | test_acc: 0.433\n",
            "epoch: 3 | loss: 1.8523 | train_acc: 0.7714 | val_acc: 0.442 | test_acc: 0.49\n",
            "epoch: 4 | loss: 1.7539 | train_acc: 0.7929 | val_acc: 0.494 | test_acc: 0.53\n",
            "epoch: 5 | loss: 1.6107 | train_acc: 0.8214 | val_acc: 0.534 | test_acc: 0.56\n",
            "epoch: 6 | loss: 1.4965 | train_acc: 0.8500 | val_acc: 0.542 | test_acc: 0.576\n",
            "epoch: 7 | loss: 1.3250 | train_acc: 0.9357 | val_acc: 0.566 | test_acc: 0.6\n",
            "epoch: 8 | loss: 1.2029 | train_acc: 0.9714 | val_acc: 0.6 | test_acc: 0.641\n",
            "epoch: 9 | loss: 1.0984 | train_acc: 0.9929 | val_acc: 0.664 | test_acc: 0.675\n",
            "epoch: 10 | loss: 0.9837 | train_acc: 1.0000 | val_acc: 0.698 | test_acc: 0.727\n",
            "epoch: 11 | loss: 0.8791 | train_acc: 1.0000 | val_acc: 0.72 | test_acc: 0.757\n",
            "epoch: 12 | loss: 0.7350 | train_acc: 1.0000 | val_acc: 0.728 | test_acc: 0.759\n",
            "epoch: 13 | loss: 0.6283 | train_acc: 1.0000 | val_acc: 0.736 | test_acc: 0.763\n",
            "epoch: 14 | loss: 0.6005 | train_acc: 1.0000 | val_acc: 0.74 | test_acc: 0.769\n",
            "epoch: 15 | loss: 0.5308 | train_acc: 1.0000 | val_acc: 0.748 | test_acc: 0.772\n",
            "epoch: 16 | loss: 0.4274 | train_acc: 1.0000 | val_acc: 0.748 | test_acc: 0.779\n",
            "epoch: 17 | loss: 0.3680 | train_acc: 1.0000 | val_acc: 0.756 | test_acc: 0.787\n",
            "epoch: 18 | loss: 0.3326 | train_acc: 1.0000 | val_acc: 0.76 | test_acc: 0.795\n",
            "epoch: 19 | loss: 0.3299 | train_acc: 1.0000 | val_acc: 0.764 | test_acc: 0.799\n",
            "epoch: 20 | loss: 0.2653 | train_acc: 1.0000 | val_acc: 0.774 | test_acc: 0.802\n",
            "epoch: 21 | loss: 0.2182 | train_acc: 1.0000 | val_acc: 0.776 | test_acc: 0.803\n",
            "epoch: 22 | loss: 0.1931 | train_acc: 1.0000 | val_acc: 0.776 | test_acc: 0.804\n",
            "epoch: 38 | loss: 0.1306 | train_acc: 1.0000 | val_acc: 0.768 | test_acc: 0.808\n",
            "epoch: 39 | loss: 0.1544 | train_acc: 1.0000 | val_acc: 0.772 | test_acc: 0.811\n",
            "epoch: 41 | loss: 0.1277 | train_acc: 1.0000 | val_acc: 0.786 | test_acc: 0.813\n",
            "epoch: 161 | loss: 0.0818 | train_acc: 1.0000 | val_acc: 0.784 | test_acc: 0.814\n",
            "epoch: 257 | loss: 0.0870 | train_acc: 1.0000 | val_acc: 0.78 | test_acc: 0.823\n",
            "epoch: 258 | loss: 0.1052 | train_acc: 1.0000 | val_acc: 0.788 | test_acc: 0.824\n",
            "epoch: 259 | loss: 0.0713 | train_acc: 1.0000 | val_acc: 0.792 | test_acc: 0.828\n"
          ]
        }
      ],
      "source": [
        "print('cuda' if torch.cuda.is_available() else 'cpu', 'is available')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(hidden=16).to(device)\n",
        "print(model)\n",
        "model.reset_parameters()\n",
        "print({i:list(j.shape) for i, j in model.named_parameters()})\n",
        "\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    pred = model(data)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss = criterion(pred[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    pred = model(data)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    correct = pred.argmax(dim=1)[mask] == data.y[mask]\n",
        "    acc = int(correct.sum()) / int(mask.sum())\n",
        "    return acc\n",
        "\n",
        "best_acc = 0\n",
        "epochs = 1000\n",
        "for epoch in range(1, epochs+1):\n",
        "    loss = train()\n",
        "    train_acc = test(data.train_mask)\n",
        "    val_acc = test(data.val_mask)\n",
        "    test_acc = test(data.test_mask)\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        print(f'epoch: {epoch} | loss: {loss.item():.4f} | train_acc: {train_acc:.4f} | val_acc: {val_acc} | test_acc: {test_acc}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "splineconv.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpfdkd4ti8R0YRedANGIjG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}